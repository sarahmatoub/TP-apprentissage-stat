---
title: "TP 2 : Arbres"
author: "Sarah Matoub"
date: "28 Septembre 2023"
toc: true
format:
  html:
    html-math-method: katex
    code-tools: true
    self-contained: true
execute:
  warning: false
---

## Mesure d'homogénéité en régression

Dans le contexte de la régression, où l'objectif est de prédire une valeur numérique plutôt que de classer des données en catégories, une mesure d'homogénéité couramment utilisée est **l'erreur quadratique moyenne (Mean Squared Error - MSE)**.

 La MSE est une mesure de la distance entre les valeurs prédites et les valeurs réelles,elle calcule la moyenne des carrés des erreurs entre les valeurs prédites et les valeurs réelles. 
 
 Plus la MSE est faible, plus le modèle de régression est précis, car cela signifie que les prédictions sont proches des valeurs réelles. 
 
 Elle est définie par l'équation :

 $$
 MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
 $$

où :

$n$ est la taille de l'échantillon.

$y_i$ est la valeur réelle de la cible pour l'échantillon $i$.

$\hat{y}_i$ est la valeur prédite de la cible pour l'échantillon $i$.

C'est une mesure d'homogénéité appropriée pour évaluer la performance des modèles de régression, car elle quantifie la précision des prédictions en termes d'erreurs entre les valeurs prédites et les valeurs réelles. Elle est largement utilisée en régression en raison de sa pertinence et de sa facilité d'interprétation.

Dans la suite de ce TP nous allons considérer le cas de la classification.

## Classification avec les arbres

Avec scikit-learn on peut construire des arbres de décision grâce au package tree. On obtient un
classifieur avec **tree.DecisionTreeClassifier**.

```{python}
from sklearn import tree
```


```{python}
#| code-fold: true
#importer les librairies nécessaires
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import rc
import random
from sklearn import tree, datasets
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from tp_arbres_source import (rand_gauss, rand_bi_gauss, rand_tri_gauss,
                              rand_checkers, rand_clown,
                              plot_2d, frontiere)


```

2) Nous allons générer des échantillons de taille n = 456 en utilisant la fonction `rand_checkers()`, en veillant à maintenir un équilibre entre les classes, comme le montre la figure @fig1 :

```{python}
#| label: fig1
#| fig-cap: "Simulation d'échantillons avec randcheckers"
#| code-fold: true

random.seed(1)
n1 = 114 
n2 = 114
n3 = 114
n4 = 114
sigma = 0.1
data4 = rand_checkers(n1, n2, n3, n4, sigma)

plt.figure(figsize=(8, 8))
plt.scatter(data4[:, 0], data4[:, 1], cmap='viridis', s=40)
plt.title('Données générées avec la fonction rand_checkers')
plt.colorbar(label='Classe')
plt.grid(True)
plt.show()
```

Nous allons à présent construire nos arbres de décision à l'aide des critères de l'entropie et l'indice de gini, avec l'attribu `criterion`:

```{python}
#| code-fold: true
dt_entropy = tree.DecisionTreeClassifier(criterion="gini")
dt_gini = tree.DecisionTreeClassifier(criterion="entropy")

data = rand_checkers(n1=114, n2=114, n3=114, n4=114, sigma=0.1)
n_samples = len(data)
X = data[:, :2] #X_train
Y = data[:,2].astype(int)  #and careful with the type (cast to int)

dt_gini.fit(X, Y)
dt_entropy.fit(X, Y) 
print("Gini criterion") #calcule les performances du score sur les données d'apprentissage
print(dt_gini.get_params())
print(dt_gini.score(X, Y))

print("Entropy criterion")
print(dt_entropy.get_params())
print(dt_entropy.score(X, Y))
```

Après avoir examiné les erreurs pour les indices de Gini et d'entropie sur les données d'entraînement, nous obtenons une valeur de 0 pour les deux. 
Cela s'explique par le fait que les échantillons que nous utilisons pour les variables à prédire sont les mêmes que ceux que nous utilisons pour les observations. En conséquence, l'algorithme apprend de manière très précise à partir de cet échantillon. Il est possible que l'algorithme s'arrête automatiquement lorsque la valeur d'erreur atteint ce seuil de 0 (en l'occurrence, 1 dans le cas d'un score parfait), car il considère que la performance est optimale à ce stade.

### Question 2

Nous allons créer deux courbes illustrant l'évolution du pourcentage d'erreurs en fonction de la profondeur maximale de l'arbre, l'une pour le critère Gini et l'autre pour l'entropie:

```{python}
#| label: fig2
#| fig-cap: "Evolution du pourcentage d'erreurs en fonction de la profondeur maximale"
#| code-fold: true
random.seed(1)
dmax = 12
scores_entropy = np.zeros(dmax)
scores_gini = np.zeros(dmax)

best_depth_entropy = None
best_score_entropy = 0.0

best_depth_gini = None
best_score_gini = 0.0


plt.figure(figsize=(15, 10))
for i in range(dmax):
    # Arbre de décision avec le critère entropy
    dt_entropy = tree.DecisionTreeClassifier(criterion="entropy", max_depth = i + 1, random_state = 0)
    dt_entropy.fit(X, Y)
    Y_pred_entropy = dt_entropy.predict(X)
    scores_entropy[i] = accuracy_score(Y, Y_pred_entropy)
    if scores_entropy[i] > best_score_entropy:
        best_score_entropy = scores_entropy[i]
        best_depth_entropy = i + 1
        
    # Arbre de décision avec le critère gini
    dt_gini = tree.DecisionTreeClassifier(criterion="gini", max_depth = i + 1, random_state = 0)
    dt_gini.fit(X, Y)
    Y_pred_gini = dt_gini.predict(X)
    scores_gini[i] = accuracy_score(Y, Y_pred_gini)
    if scores_gini[i] > best_score_gini:
        best_score_gini = scores_gini[i]
    best_depth_gini = i + 1

    plt.subplot(3, 4, i + 1)
    frontiere(lambda x: dt_gini.predict(x.reshape((1, -1))), X, Y, step=50, samples=False)
    plt.title(f'Depth{ i + 1 }')
plt.draw()


plt.figure()
plt.plot(range(1, dmax + 1), 1 - scores_entropy, label="Accuracy score (Entropy)")
plt.plot(range(1, dmax + 1), 1 - scores_gini, label="Accuracy score (Gini)")
plt.xlabel("Max depth")
plt.ylabel("Accuracy score")
plt.legend()
plt.grid(True)
plt.draw()

print("Best depth for Entropy: ", best_depth_entropy)
print("Best accuracy with Entropy: ", best_score_entropy)
print("Best depth for Gini: ", best_depth_gini)
print("Best accuracy with Gini: ", best_score_gini)

```

En observant la @fig2, il devient évident que plus la profondeur de l'arbre est grande, plus nous nous approchons d'une erreur de 0, dans cette illustration, nous avons utilisé une profondeur maximale de 12.
En réalité, au-delà de cette valeur, l'erreur devient négligeable, voire inexistante. Cette tendance est clairement observable sur les courbes.

Il est également important de noter qu'en utilisant un arbre avec une profondeur faible, l'erreur est considérablement élevée. Cela est dû au fait que, dans des cas où les données sont bien réparties et où l'on ne peut effectuer qu'une seule coupe, nous obtenons deux classes extrêmement hétérogènes.

### Question 3

Nous allons présenter la classification obtenue en utilisant la profondeur qui minimise le pourcentage d'erreurs basées sur l'entropie, en utilisant les fonctions `plot_2d()` et `frontiere()` du fichier source :

```{python}
#| label: fig3
#| fig-cap: "Classification obtenue avec la meilleur profondeur"
#| code-fold: true
random.seed(1234)
# Créer un arbre de décision avec la meilleure profondeur pour l'entropie
best_tree_entropy = DecisionTreeClassifier(
    criterion="entropy", max_depth=best_depth_entropy, random_state=0)
best_tree_entropy.fit(X, Y)
# Afficher la classification obtenue avec la profondeur optimale (Entropy)
plt.figure(figsize=(8, 8))
plt.figure()
frontiere(lambda x: dt_entropy.predict(x.reshape((1, -1))), X, Y, step=100,
          samples=True) 
plt.title("Best frontier with entropy criterion")
plt.draw()
print("Best scores with entropy criterion: ", dt_entropy.score(X, Y))
```

On voit que la plupart des données d'apprentissage sont correctement classées, ce qui témoigne d'une bonne performance globale du modèle. Cependant, il est important de noter que les frontières de décision obtenues sont assez complexes. Ceci est principalement dû au fait qu'une profondeur maximale élevée signifie que nous autorisons une découpe très fine de l'espace, ce qui peut conduire à des frontières de décision complexes et détaillées.

### Question 4

Nous allons utiliser la fonction `export_graphviz()` du module `tree` pour exporter le graphique de l'arbre obtenu dans la question précédente au format PDF. 


```{python}
#| code-fold: true
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
import graphviz
from graphviz import Source

import os
os.environ["PATH"] += os.pathsep + 'D:/Program Files (x86)/Graphviz2.38/bin/'

best_tree_entropy = DecisionTreeClassifier(criterion="entropy", max_depth=best_depth_entropy, random_state=0)
best_tree_entropy.fit(X, Y)
# On exporte l'arbre au format DOT
donnes = export_graphviz(best_tree_entropy)
# On crée un objet Graphviz à partir du fichier DOT
graph = graphviz.Source(donnes)
graph.render("best_tree_entropy", format = "pdf")
```

Le fichier exporté sera nommé *best_tree_entropy.pdf* et sera enregistré dans le dossier **Plots** du dépôt Git de ce TP.

La lecture d'un arbre de décision est assez intuitive et suit un schéma hiérarchique.
Il commence par un noeud appelé "la racine" , qui représente le tout premier point de décision de l'arbre. À partir de la racine, il y a généralement deux noeuds enfants. Chaque noeud qui n'est pas une feuille a lui-même deux noeuds enfants, et cela se répète jusqu'à ce que nous atteignions les noeuds terminaux, également appelés "feuilles", où les décisions sont prises.

La manière de lire un arbre de décision est la suivante : 

- Si la condition spécifiée au niveau d'un noeud est satisfaite pour une observation donnée, nous suivons la branche de gauche de ce noeud. En revanche, si la condition n'est pas satisfaite, nous empruntons la branche de droite. En suivant ces branches de noeud en noeud, de la racine aux feuilles, nous finissons par atteindre une feuille qui indique la décision ou la prédiction finale basée sur les conditions remplies par l'observation.

### Question 5

Nous allons générer un nouvel ensemble de données contenant n = 160 échantillons, répartis en 40 exemplaires de chaque classe à l'aide de la fonction `rand_checkers()`. Ensuite, nous évaluerons les arbres de décision préalablement entraînés en calculant la proportion d'erreurs commises sur cet échantillon de test:

```{python}
#| code-fold: true
# Créer un nouvel échantillon de test avec 160 données (40 de chaque classe)
random.seed(1)
new_data = rand_checkers(n1=40, n2=40, n3=40, n4=40, sigma=0.1)

# Séparer les caractéristiques et les étiquettes
X_new = new_data[:, :2]
Y_new = new_data[:, 2].astype(int)

# Évaluer les modèles sur le nouvel échantillon de test
error_rate_entropy = 1 - best_tree_entropy.score(X_new, Y_new)

best_tree_gini = DecisionTreeClassifier(criterion="gini", max_depth=best_depth_gini, random_state=0)
best_tree_gini.fit(X_new, Y_new)

error_rate_gini = 1 - best_tree_gini.score(X_new, Y_new)

print("Proportion d'erreurs sur le nouvel échantillon (Entropy): {:.2f}%".format(error_rate_entropy * 100))
print("Proportion d'erreurs sur le nouvel échantillon (Gini): {:.2f}%".format(error_rate_gini * 100))

dmax = 12
scores_entropy = np.zeros(dmax)
scores_gini = np.zeros(dmax)
plt.figure(figsize=(15, 10))

for i in range(dmax):
    
    # Créer un arbre de décision avec une profondeur maximale variable (entropy)
    dt_entropy = DecisionTreeClassifier(criterion="entropy", max_depth=i + 1)
    dt_entropy.fit(X_new, Y_new)
    scores_entropy[i] = 1 - dt_entropy.score(X_new, Y_new)

    dt_gini = DecisionTreeClassifier(criterion="gini", max_depth = i + 1)
    dt_gini.fit(X_new, Y_new)
    scores_gini[i] = 1 - dt_gini.score(X_new, Y_new)
    
    plt.subplot(3, 4, i + 1)
    frontiere(lambda x: dt_gini.predict(x.reshape((1, -1))), X_new, Y_new, step=50, samples=False)

plt.figure()
plt.plot(range(1, dmax + 1), scores_entropy, label="Entropy")
plt.plot(range(1, dmax + 1), scores_gini, label="Gini")
plt.xlabel('Max depth')
plt.ylabel('Error Rate')
plt.title("Testing error")
plt.legend()
plt.show()

print("Proportion d'erreurs sur le nouvel échantillon (Entropy): {:.2f}%".format(error_rate_entropy * 100))
print("Proportion d'erreurs sur le nouvel échantillon (Gini): {:.2f}%".format(error_rate_gini * 100))

```

On remarque que la proportion d'erreurs est nettement plus élevée pour l'arbre de décision basé sur l'entropie que pour celui basé sur l'indice de Gini, suggérant ainsi que l'arbre basé sur gini offre une précision supérieure lors de la prédiction des échantillons de test par rapport à l'arbre basé sur l'entropie.

### Question 6

Nous allons reprendre ce qui a été fait précédement avec le dataset **DIGITS** :

```{python}
#| code-fold: true
#| label: fig4
#| fig-cap: "Pourcentage d'erreur en fonction de la profondeur maximale sur les données d'entrainement"
from sklearn import datasets
from sklearn.model_selection import train_test_split
# Import the digits dataset
digits = datasets.load_digits()

n_samples = len(digits.data)
d = digits.images.reshape((n_samples, -1))
# Diviser l'ensemble de données en ensembles d'entraînement et de test (80% - 20%)

X_train, X_test, Y_train, Y_test = train_test_split(d,
digits.target, test_size = 0.2, shuffle=False)

dmax = 12
scores_entropy = np.zeros(dmax)
scores_gini = np.zeros(dmax)

for i in range(dmax):
    # Arbre de décision pour l'entropie
    dt_entropy = DecisionTreeClassifier(criterion="entropy", max_depth = i + 1)
    dt_entropy.fit(X_train, Y_train)
    scores_entropy[i] = 1 - dt_entropy.score(X_train, Y_train)
    
    #Arbre de décision pour gini
    dt_gini =  DecisionTreeClassifier(criterion="gini", max_depth = i + 1)
    dt_gini.fit(X_train, Y_train)
    scores_gini[i] = 1 - dt_gini.score(X_train, Y_train)
    
plt.figure()
plt.plot(scores_entropy, label = "score entropy")
plt.plot(scores_gini, label = "score gini")
plt.legend()
plt.xlabel("Max Depth")
plt.ylabel("Accuracy score")
plt.draw()
```

La figure @fig4 montre que le taux d'erreurs sur les données d'apprentissage diminue à mesure que la profondeur de l'arbre augmente. Il atteint finalement 0 % au-delà d'un certain seuil de profondeur dans les deux cas.

Evaluons maintenant la performance des arbres de décision préalablement entraînés en calculant la proportion d'erreurs qu'ils commettent sur l'échantillon de test :

```{python}
#| code-fold: true
#| label: fig5
#| fig-cap: "Pourcentage d'erreur en fonction de la profondeur maximale sur les données de test"
dmax = 12
scores_entropy = np.zeros(dmax)
scores_gini = np.zeros(dmax)

for i in range(dmax):
    dt_entropy = tree.DecisionTreeClassifier(criterion="entropy", max_depth = i + 1)
    dt_entropy.fit(X_train,Y_train)
    scores_entropy[i] = 1 - dt_entropy.score(X_test, Y_test)

    dt_gini = tree.DecisionTreeClassifier(criterion="gini", max_depth = i+1)
    dt_gini.fit(X_train,Y_train)
    scores_gini[i] = 1 - dt_gini.score(X_test,Y_test)


plt.figure()
plt.plot(scores_entropy, label="entropy")
plt.plot(scores_gini, label="gini")
plt.legend()
plt.xlabel("Max Depth")
plt.ylabel("Accuracy Score")
plt.draw()
print("Entropy criterion scores : ", scores_entropy)
print("Gini criterion scores : ", scores_gini)
```

En analysant la figure @fig5, nous constatons que le taux d'erreurs diminue jusqu'à une certaine profondeur, après quoi il commence à augmenter légèrement. Contrairement aux données d'apprentissage, le taux d'erreurs sur l'échantillon de test ne semble pas converger vers 0, il persiste toujours des erreurs de prédiction.

Nous allons exporter le graphique de l'arbre obtenu comme nous l'avions fait à la question 4.

```{python}
#| output: false
dot_data2 = tree.export_graphviz(dt_entropy, out_file=None)
graph = graphviz.Source(dot_data2)
graph.render("Plots\Arbre_question6", format="pdf")
```

### Question 7

Nous allons utiliser la fonction `sklearn.cross_validation.cross_val_score()` pour évaluer ses performances sur le jeu de données **digits** en ajustant la profondeur de l'arbre de décision de manière variée. Cette fonction sera utile pour déterminer la profondeur optimale de l'arbre :

```{python}
#| code-fold: true
from sklearn.model_selection import cross_val_score

# Profondeurs maximales à tester
max_depths = np.arange(1, 16, 1)

# scores de validation croisée
cv_scores = []

# Tester chaque profondeur maximale
for depth in max_depths:
    # Initialiser et entraîner l'arbre de décision avec le critère d'Entropy
    tree_classifier = DecisionTreeClassifier(criterion="entropy", max_depth=depth, random_state=0)
    
    # Effectuer une validation croisée avec 5 plis
    scores = cross_val_score(tree_classifier, X, Y, cv=5)
    
    # Calculer la moyenne des scores de validation croisée
    mean_score = scores.mean()
    
    # Ajouter le score moyen à la liste des scores
    cv_scores.append(mean_score)

# Trouver la meilleure profondeur maximale avec le score le plus élevé
best_depth_index = cv_scores.index(max(cv_scores))
best_depth = max_depths[best_depth_index]


for depth, score in zip(max_depths, cv_scores):
    print("Profondeur maximale = {}, Score de validation croisée moyen = {:.4f}".format(depth, score))
    
print("Meilleure profondeur maximale (Entropy) = {}, Score de validation croisée moyen = {:.4f}".format(best_depth, max(cv_scores)))
```

L'analyse de ces résultats révèle que lorsque la profondeur maximale atteint 12, les scores de validation croisée se stabilisent à 0.8146, ce qui représente le meilleur score possible. Ce qui signifie que la profondeur optimale pour cet ensemble de données est de 12. Au-delà de cette valeur, les scores de validation croisée semblent plafonner ou présenter une légère baisse, ce qui pourrait indiquer un surajustement du modèle aux données d'entraînement.

Conclusion : pour le jeu de données **digits**, il est raisonnable de prendre une profondeur maximale de 12. Cette profondeur représente un compromis idéal entre la capacité du modèle à saisir la complexité des données et sa capacité à réaliser des prédictions précises sur de nouvelles données, ce qui contribue à obtenir la meilleure performance de prédiction.

### Question 8

Nous allons afficher la courbe d’apprentissage (en : learning curve) pour les arbres de décisions sur le même jeu de données :

```{python}
#| code-fold: true
#| label: "fig6"
#| fig-cap: "Courbe d'apprentissage pour le meilleur arbre de décision"
from sklearn.model_selection import learning_curve
from sklearn.model_selection import train_test_split

# Charger l'ensemble de données digits
digits = datasets.load_digits()
X = digits.data
Y = digits.target

# Diviser l'ensemble de données en ensembles d'entraînement (80%) et de test (20%)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

# Créer un classificateur d'arbre de décision avec la meilleure profondeur
dt = DecisionTreeClassifier(criterion='entropy', max_depth=best_depth)

# Calculer la courbe d'apprentissage
n_samples, train_scores, test_scores = learning_curve(dt, X_train, Y_train, cv=5)

# Calculer les moyennes et les écarts types des scores
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

# Tracer la courbe d'apprentissage
plt.figure()
plt.grid()
plt.fill_between(n_samples, train_scores_mean - 1.96 * train_scores_std,
                 train_scores_mean + 1.96 * train_scores_std, alpha=0.1, label="Train")
plt.fill_between(n_samples, test_scores_mean - 1.96 * test_scores_std,
                 test_scores_mean + 1.96 * test_scores_std, alpha=0.1, label="Test")
plt.plot(n_samples, train_scores_mean, 'o-', label="Score d'entraînement")
plt.plot(n_samples, test_scores_mean, 'o-', label="Score de validation croisée")
plt.legend(loc="lower right")
plt.xlabel("Taille de l'échantillon d'entraînement")
plt.ylabel("Accuracy")
plt.title("Courbe d'apprentissage pour le meilleur arbre de décision")
plt.show()
```

À la lecture de la figure @fig6, il est évident que le modèle d'arbre de décision atteint un score d'entraînement parfait de 1, ce qui signifie qu'il peut ajuster de manière précise les données d'entraînement, mais cela soulève la possibilité de surajustement. En revanche, le score de validation croisée est compris entre 0.8 et 0.9, ce qui est encourageant et suggère que le modèle généralise bien sur des données inconnues. Cependant, le fait que le score de validation croisée n'atteigne pas 1 indique qu'il subsiste une variabilité naturelle dans les données. Globalement, la figure révèle un équilibre entre l'ajustement aux données d'entraînement et la capacité à généraliser, mais il convient de surveiller la complexité du modèle pour éviter un surajustement excessif.







